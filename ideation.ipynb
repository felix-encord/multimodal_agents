{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hyperlinks(chunk: str):\n",
    "    # Pattern to match standard links: [text](url)\n",
    "    standard_link_pattern = r'\\[([^\\]]+)\\]\\(([^)]+)\\)'\n",
    "    \n",
    "    # Pattern to match image links: ![alt](url)\n",
    "    image_link_pattern = r'!\\[([^\\]]*)\\]\\(([^)]+)\\)'\n",
    "    \n",
    "    def replace_links(match):\n",
    "        text, url = match.groups()\n",
    "        # Check if it's an image link\n",
    "        if match.re.pattern == image_link_pattern:\n",
    "            return f'<img src=\"{url}\" alt=\"{text}\">'\n",
    "        # For standard links, keep the original text\n",
    "        return text\n",
    "    \n",
    "    # First process image links\n",
    "    result = re.sub(image_link_pattern, replace_links, chunk)\n",
    "    \n",
    "    # Then process standard links\n",
    "    result = re.sub(standard_link_pattern, replace_links, result)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_image_urls(text):\n",
    "    \"\"\"\n",
    "    Extracts image URLs from <img src=\"...\"> tags and splits the text around these tags.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text containing image tags\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - List of extracted image URLs\n",
    "            - List of text segments split around image tags\n",
    "    \"\"\"\n",
    "    # Regular expression to match <img src=\"...\"> tags\n",
    "    pattern = r'<img\\s+src=\"([^\"]+)\"[^>]*>'\n",
    "    \n",
    "    # Find all matches of image URLs\n",
    "    urls = re.findall(pattern, text)\n",
    "    \n",
    "    # Split the text using the image tag pattern\n",
    "    text_segments = [segment for segment in re.split(pattern, text) if segment and segment not in urls]\n",
    "    \n",
    "    \n",
    "    return urls, text_segments\n",
    "\n",
    "def extract_image_urls_v2(text):\n",
    "    \"\"\"\n",
    "    Extracts image URLs from <img src=\"...\"> tags and splits the text around these tags.\n",
    "    Also removes <div> sections that may contain or surround these tags.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text containing image tags and div sections\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - List of extracted image URLs\n",
    "            - List of text segments split around image and div tags\n",
    "    \"\"\"\n",
    "    # Combined regex pattern to match and remove:\n",
    "    # 1. Entire <div> sections (including nested content)\n",
    "    # 2. <img> tags\n",
    "    pattern = r'(<div[^>]*>.*?</div>|<img\\s+src=\"[^\"]+?\"[^>]*>)'\n",
    "    \n",
    "    # Find all URLs within img tags\n",
    "    img_pattern = r'<img\\s+src=\"([^\"]+)\"[^>]*>'\n",
    "    urls = re.findall(img_pattern, text)\n",
    "    \n",
    "    # Split the text and filter out empty segments and urls\n",
    "    text_segments = [\n",
    "        segment.strip() \n",
    "        for segment in re.split(pattern, text, flags=re.DOTALL) \n",
    "        if segment and \n",
    "           segment not in urls and \n",
    "           not re.match(r'<(div|img)', segment.strip())\n",
    "    ]\n",
    "    \n",
    "    return urls, text_segments\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_image_urls_v3(text):\n",
    "    \"\"\"\n",
    "    Extracts image URLs from <img src=\"...\"> tags and splits the text around these tags.\n",
    "    \n",
    "    Processing of <div> sections:\n",
    "      - If a <div> does NOT contain an <img src=\"...\">, it is removed completely.\n",
    "      - If a <div> DOES contain an <img src=\"...\">, it is replaced with just the <img> tag(s).\n",
    "        This preserves the image as a splitting delimiter while discarding any extra div content.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text containing image tags and div sections.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - List of extracted image URLs.\n",
    "            - List of text segments split around image tags.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract all image URLs from the original text.\n",
    "    img_pattern = r'<img\\s+src=\"([^\"]+)\"[^>]*>'\n",
    "    urls = re.findall(img_pattern, text, flags=re.DOTALL)\n",
    "    \n",
    "    # Step 2: Process all <div>...</div> blocks.\n",
    "    def div_replacer(match):\n",
    "        div_block = match.group(0)\n",
    "        # If this <div> contains at least one <img src=\"...\">, extract the image tags.\n",
    "        if re.search(r'<img\\s+src=\"[^\"]+\"', div_block):\n",
    "            imgs = re.findall(r'<img\\s+src=\"[^\"]+\"[^>]*>', div_block, flags=re.DOTALL)\n",
    "            # Replace the entire div with only its <img> tag(s).\n",
    "            return ''.join(imgs)\n",
    "        else:\n",
    "            # Otherwise, remove the <div> entirely (and do not split on it).\n",
    "            return ''\n",
    "    \n",
    "    # Replace all <div> sections using the helper.\n",
    "    text = re.sub(r'<div[^>]*>.*?</div>', div_replacer, text, flags=re.DOTALL)\n",
    "    \n",
    "    # Step 3: Split the text on <img> tags.\n",
    "    segments = [seg.strip() for seg in re.split(r'<img\\s+src=\"[^\"]+\"[^>]*>', text, flags=re.DOTALL) if seg.strip()]\n",
    "    \n",
    "    return urls, segments\n",
    "\n",
    "#TODO move if text = .,'',| outside of loop to do at beginning / fix root issue causing this, also add remove import x regex func\n",
    "def match_image_to_text(urls,input_text_segments,original_markdown_path):\n",
    "\n",
    "    text_segments = [remove_yaml_header(x) for x in input_text_segments]\n",
    "\n",
    "    if len(urls) == 0:\n",
    "        return pd.DataFrame({\"image url\" : [], \"above text\" : [],\"below text\": [], \"source markdown file\" : []})\n",
    "    \n",
    "    \n",
    "    elif len(urls) == 1:\n",
    "\n",
    "        #Encord text upload doesnt like empty .txt files\n",
    "        if text_segments[0] == '':\n",
    "            text_segments[0] = '---'\n",
    "\n",
    "        if len(text_segments) == 1:\n",
    "            return pd.DataFrame({\"image url\" : urls, \"above text\" : [text_segments[0]],\"below text\": ['---'], \"source markdown file\" : [original_markdown_path]})\n",
    "        \n",
    "        elif len(text_segments) == 2:\n",
    "\n",
    "            return pd.DataFrame({\"image url\" : urls, \"above text\" : [text_segments[0]],\"below text\": [text_segments[1]], \"source markdown file\" : [original_markdown_path]})\n",
    "\n",
    "        else:\n",
    "            raise ValueError\n",
    "            \n",
    "    else:\n",
    "        \n",
    "\n",
    "        try:\n",
    "            upper_text_for_url = []\n",
    "            lower_text_for_url = []\n",
    "\n",
    "            pointer = 0\n",
    "\n",
    "            #TODO this assumes text always precedes image in md file\n",
    "\n",
    "            while pointer < len(urls):\n",
    "\n",
    "                above_text = text_segments[pointer]\n",
    "\n",
    "                if above_text == '' or above_text == '|' or above_text == '.':\n",
    "                    above_text = '---'\n",
    "                upper_text_for_url.append(above_text)\n",
    "\n",
    "                if pointer + 1 < len(text_segments):\n",
    "                    below_text = text_segments[pointer+1]\n",
    "\n",
    "                    #encord txt upload doesnt like empty .txt\n",
    "                    if below_text == '' or below_text == '|' or below_text == '.':\n",
    "                        below_text = '---'\n",
    "                    lower_text_for_url.append(below_text)\n",
    "                else:\n",
    "                    lower_text_for_url.append('---')\n",
    "                \n",
    "                pointer +=1\n",
    "            \n",
    "            return pd.DataFrame({\"image url\" : urls, \"above text\" : upper_text_for_url,\"below text\": lower_text_for_url, \"source markdown file\" : [original_markdown_path]*len(urls)})\n",
    "        \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(original_markdown_path)\n",
    "            print(urls)\n",
    "            print(text_segments)\n",
    "            print(f'url length: {len(urls)} seg length: {len(text_segments)}')\n",
    "            return pd.DataFrame({\"image url\" : [], \"above text\" : [],\"below text\": [], \"source markdown file\" : []})\n",
    "    \n",
    "def remove_yaml_header(text):\n",
    "    \"\"\"\n",
    "    Removes the YAML header from the input text.\n",
    "    The YAML header is defined as the section at the beginning of the text \n",
    "    that starts with a line containing only '---' and ends with another such line.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text that may contain a YAML header.\n",
    "    \n",
    "    Returns:\n",
    "        str: The text with the YAML header removed.\n",
    "    \"\"\"\n",
    "    # Pattern explanation:\n",
    "    # ^---\\s*\\n    => Matches a line that starts with '---', possibly followed by whitespace, then a newline.\n",
    "    # .*?         => Non-greedily matches any characters (including newlines, due to DOTALL flag).\n",
    "    # \\n---\\s*\\n? => Matches a newline, then a line that starts with '---' (optionally followed by whitespace)\n",
    "    #                and an optional newline after it.\n",
    "    pattern = r'^---\\s*\\n.*?\\n---\\s*\\n?'\n",
    "    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_code(chunk : str):\n",
    "    code_pattern = r'import([\\s\\S]*?)/>'\n",
    "    return re.sub(code_pattern,'',chunk)\n",
    "\n",
    "\n",
    "def remove_backtick_content(text):\n",
    "    \"\"\"\n",
    "    Removes all content enclosed within matching backticks from the text.\n",
    "    This will remove both inline code (e.g. `code`) and multi-line code blocks \n",
    "    (e.g. ```code block```).\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with all backtick-enclosed segments removed.\n",
    "    \"\"\"\n",
    "    # This pattern captures one or more backticks, then any content (non-greedily),\n",
    "    # until the same sequence of backticks appears again.\n",
    "    pattern = r'(`+).*?\\1'\n",
    "    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform-documentation/Annotate/annotate-projects/annotate-manual-qa-projects.mdx\n",
      "['https://storage.googleapis.com/docs-media.encord.com/static/img/projects/performance-new-current-toggle.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/project-dashboard/performance/performance-dashboard-date-filter-and-charts.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/project-dashboard/performance/performance-dashboard-annotor-and-reviewer-table.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/project-dashboard/performance/performance-dashboard-objects-and-classifications-table.png']\n",
      "[\"Performance - Details\\n\\nThe _Details_ tab of the performance dashboard gives a more detailed view of your team's labeling and productivity. This section will cover manual QA projects. The below details will be displayed for Manual QA projects.\\n\\n<Warning>The _Details_ tab of the performance dashboard only shows information for labels created in the Label Editor. Labels submitted via the SDK **will not be** shown on the _Details_ tab. This includes labels that were submitted using the SDK, and edited in the Label Editor. </Warning>\\n\\n<Tip>You can specify a range of dates, as well as whether statistics should be displayed for labels, or instances. More information on instances and labels can be found here.</Tip>\"]\n",
      "url length: 4 seg length: 1\n",
      "platform-documentation/Annotate/annotate-projects/annotate-training-projects.mdx\n",
      "['https://storage.googleapis.com/docs-media.encord.com/static/img/projects/training/working_flow/at_lifecycle4-adjusting_score.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/training/working_flow/at_lifecycle3_before-score-reconfig.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/training/working_flow/at_lifecycle5_after-score-reconfig.png']\n",
      "[\"4. Adjust the benchmark function and re-calculate scores\\n\\nIf you feel that annotator score distributions do not correctly reflect the skill displayed, the benchmark function can be adjusted and annotator scores can be recalculated.\\n\\nGo the _Settings_ page, and find the section marked 'Benchmark scoring function'. Press the **Edit** button to enable the function's weight editor and change the values to match your new plan. Finally, press **Save** in the upper right to persist the new function configuration.\", \"To see the changes applied against previous submissions, return to the 'Summary' page and press the **Re-calculate scores** button. If a given annotator's annotations were affected by the weighting change, the 'Benchmark results' column will change to reflect their new score with the new weights! In this case, we see the  score of an annotator, on the left and right respectively before and after we changed the scoring function (as above), and pressed the **Re-calculate scores** button. The annotator's change in score is noticeable, but doesn't seem to change his performance from unskilled to skilled. Likely, this annotator should undergo another round of training.\"]\n",
      "url length: 3 seg length: 2\n",
      "platform-documentation/Annotate/annotate-projects/annotate-manage-annotation-projects.mdx\n",
      "['https://storage.googleapis.com/docs-media.encord.com/static/img/projects/performance-new-current-toggle.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/projects-new-performance-dashboard-labeled.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/projects-new-performance-dashboard-2.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/instance-label-actions-slider.gif', 'https://storage.googleapis.com/docs-media.encord.com/static/img/workflows/workflows-team-collaborators.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/performance-new-current-toggle.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/project-dashboard/performance/performance-dashboard-date-filter-and-charts.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/project-dashboard/performance/performance-dashboard-annotor-and-reviewer-table.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/projects/project-dashboard/performance/performance-dashboard-objects-and-classifications-table.png']\n",
      "[\"Performance (Legacy)\\n\\n<Warning>\\nThis dashboard shows legacy Analytics. To see Detailed analytics relating to Workflow Projects see the Analytics section.\\n</Warning> \\n\\n**Performance - Summary**\\n\\nThe _Summary_ tab of the performance dashboard provides an overview of your team's manual labeling and productivity.\\n\\n<Warning>The _Summary_ tab only displays actions taken in the Label Editor. Actions taken in the SDK **will not** be displayed.</Warning>\", '**Task actions over time**\\n\\nView the number of tasks in a project that have been approved, rejected, and submitted for review over a given period of time.\\n\\n- The height of a bar represents the total number of tasks.\\n- The height of each color within a bar represents the number of approved, rejected, and submitted tasks.', \"- **A**:  Set the time period you would like to see displayed by selecting a range of dates.\\n- **B**: The **Hide days without any actions** toggle removes all days at which no actions were taken from the view. \\n- **C**: Download a CSV file of the data. \\n- **D**: Display the data as a bar chart, or a table. While the chart provides a clear visual representation, the table provides exact figures for a more detailed picture of your team's performance. \\n\\n\\n**Instance Label actions over time**\\n\\nView the number of instance label actions in a project that have been approved, rejected, and submitted for review over a given period of time.\", \"- **A**: Set the time period you would like to see displayed by selecting a range of dates.\\n- **B**: Download a CSV file of the data. \\n- **C**: Display the data as a bar chart, or a table. While the chart provides a clear visual representation, the table provides exact figures for a more detailed picture of your team's performance. \\n\\nWithin your specified time period, you can choose which dates to display by using the slider located beneath the graph.\", \"**Team collaborators**\\n\\nThe 'Team collaborators' section shows the duration of time each project collaborator spend working on a given file.\", \"**A.** 'Data file' displays session time collaborators spent working on individual files. 'Project' displays session time collaborators have spent working on the project.  \\n\\n**B.** Table entries can be filtered according to dates by clicking the range of dates, and selecting the start and end date of the period you would like to see table entries displayed for.\\n\\n**C.** Table entries can be downloaded in CSV format by clicking the **Download CSV** button.\\n\\n**D.** When lots of entries are present they will be split across a number of different pages. The number of table entries per table can be adjusted.\\n\\n---\\n\\n**Performance - Details**\\n\\nThe _Details_ tab of the performance dashboard gives a more detailed view of your team's labeling and productivity. This section will cover manual QA projects. The below details will be displayed for Manual QA projects.\\n\\n<Warning>The _Details_ tab of the performance dashboard only shows information for labels created in the Label Editor. Labels submitted via the SDK **will not be** shown on the _Details_ tab. This includes labels that were submitted using the SDK, and edited in the Label Editor. </Warning>\\n\\n<Tip>You can specify a range of dates, as well as whether statistics should be displayed for labels, or instances. More information on instances and labels can be found here.</Tip>\", \"**Submissions chart**\\n\\nThe submissions chart displays the number of submitted labels or instances over the specified time period. The chart can be filtered to show submissions for specific annotators or classes. \\n\\nIf you filter on both **Annotators** and **Classes** then the resulting chart will show the submission statistics for the selected annotators and for selected labels. \\n\\n\\n**Reviews chart**\\n\\nThe reviews chart displays the cumulative number of accepted and rejected labels or instances over the specified time period.\\n\\n\\n**Annotator's table**\\n\\nThe annotator's table displays all the relevant statistics for all annotators in a Project. It can be filtered on classes to show annotator statistics only for the selected classes.\\n\\n- **User**: The annotator's email.\\n- **Rejection rate**: Percentage of their labels or instances that have been rejected in the review process.\\n- **Submitted labels / instances**: Number of labels or instances that the annotator has submitted for review\\n  - Repeated submissions are not counted.\\n- **Accepted labels / instances**: Number of labels or instances that the annotator created that passed the review process.\\n- **Rejected labels / instances**: Number of labels or instances that the annotator created that we're rejected during the review process. Note that this can be higher than the number of submitted labels / instances since a label or instance can be rejected multiple times during the review process but the submission will only be logged once.\\n- **Total session time**: Time spent labeling.\\n\\n\\n**Reviewers table**\\n\\n- **User**: The reviewers email.\\n- **Rejection rate**: Percentage of labels or instances that they rejected in the review process.\\n- **Accepted labels / instances**: Number of labels or instances that the reviewer accepted.\\n- **Rejected labels / instances**: Number of labels or instances that the reviewer rejected.\\n- **Total session time**: Time spent reviewing.\\n\\n\\n**Objects and classifications table**\\n\\nEach row in the objects and classifications table can be expanded to show statistics on attributes. \\n\\n- **Class**: The class name.\\n- **Rejection rate**: Percentage of labels or instances rejected in the review process.\\n- **Reviewed labels / instances**: Number of labels or instances of the class that have gone through the review process.\\n- **Accepted labels / instances**: Number of labels or instances of the class that have passed the review process.\\n- **Rejected labels / instances**: Number of labels or instances of the class that failed the review process.\\n- **Avg. time to annotate**: Average time spent annotating this class.\\n\\n---\"]\n",
      "url length: 9 seg length: 7\n",
      "platform-documentation/Active/active-basics/active-video.mdx\n",
      "['https://storage.googleapis.com/docs-media.encord.com/static/img/active/filters-labels-metrics/formula-01.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/active/filters-labels-metrics/inconsistent-track-01.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/active/filters-labels-metrics/inconsistent-track-02.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/active/filters-labels-metrics/inconsistent-track-03.png', 'https://storage.googleapis.com/docs-media.encord.com/static/img/active/filters-labels-metrics/formula-02.png']\n",
      "['Find Inconsistent Tracks\\n\\n\"Inconsistent tracks\" are cases an object is being tracked (labelled) across a range of frames, but the occurrence of the label changes part way through tracking the object. For example, you want to track two cars across an entire video. At some point in the video, the labels on the cars are swapped OR a new label gets applied to one or both of the cars. \\n\\nFor example, for two neighboring frames, say $ and , we assume that for every object  in frame , the object  in frame  with the highest IOU to  should have the same \\n\\nFor every object in frame , the algorithm works by computing the IOU between that object and every object in frame  to select the one with the highest IOU. If those two objects have the same objectHash, all good, score will be zero. There’s nothing to flag. If, on the other hand, the two objects do not share the same objectHash, it’s flagged by setting the score to the IOU between the two. \\n\\nThink of  as the best match (highest IOU) in the following frame.', 'In the above, we use  as a shorthand for objectHash.\\n\\nIn turn, \\n\\n- A score equal to 0 means that no issues were found.\\n- A score close to zero (but not zero) means that there is inconsistency in the object hashes but the objects do not overlap much, so it is less likely to be an actual label error.\\n- A score closer to one means that the two objects have a high overlap and inconsistency in object hash.\\n\\n**Example**\\n\\nIn this example, one track is inconsistent. The green guy has had objectHash  for a while, and suddenly it changes to . Also indicated here by color (which would not actually be the case in the editor).', '**Special case**\\n\\nThis algorithm also works for classifications. However, in that situation, the IOU falls back to the identity function']\n",
      "url length: 5 seg length: 3\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for markdown_path in Path('').rglob('*.mdx'):\n",
    "\n",
    "    with open(markdown_path, 'r', encoding='utf-8') as file:\n",
    "        mdx_raw_string = file.read()\n",
    "    \n",
    "   # mdx_raw_string = clean_header(mdx_raw_string)\n",
    "    mdx_raw_string = remove_hyperlinks(mdx_raw_string)\n",
    "    mdx_raw_string = remove_backtick_content(mdx_raw_string)\n",
    "    # mdx_raw_string = remove_code(mdx_raw_string)\n",
    "\n",
    "    pattern = r'^(#{1,2})(?!#{1,})(.+)$'\n",
    "    chunks = [x for x in re.split(pattern, mdx_raw_string, flags=re.MULTILINE) if len(x) > 0]\n",
    "    \n",
    "    chunks = [x for x in mdx_raw_string.split('#') if len(x) > 0]\n",
    "    for chunk in chunks:\n",
    "        urls,segments = extract_image_urls_v3(chunk)\n",
    "        df = match_image_to_text(urls,segments,markdown_path)\n",
    "        df_list.append(df)\n",
    "\n",
    "filtered_df_list = [x for x in df_list if len(x) > 0]\n",
    "test_df = pd.concat(filtered_df_list,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('raw_multimodal_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['image url'].apply(lambda x : 'gif' in x).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i,row in enumerate(test_df.iterrows()):\n",
    "\n",
    "    atext = row[1]['above text']\n",
    "    btext = row[1]['below text']\n",
    "\n",
    "    with open(f'above_text/above_text_{i}.txt','w') as output:\n",
    "        output.write(atext)\n",
    "    with open(f'below_text/below_text_{i}.txt','w') as output:\n",
    "        output.write(btext)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_json = { \"images\" : []}\n",
    "\n",
    "for i,row in enumerate(test_df.iterrows()):\n",
    "\n",
    "    img_url = row[1]['image url']\n",
    "\n",
    "    img_obj = {\n",
    "        \"objectUrl\": img_url,\n",
    "        \"title\" : img_url.split('/')[-1],\n",
    "        \"clientMetadata\" : {\"id\" : str(i), \"Data_Type\" : \"Image\"}\n",
    "    }\n",
    "\n",
    "    if 'gif' not in img_url:\n",
    "        upload_json['images'].append(img_obj)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('doc_images.json','w',encoding='utf-8') as f:\n",
    "    json.dump(upload_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encord import EncordUserClient\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped 0\n",
      "skipped 1\n",
      "skipped 2\n",
      "skipped 3\n",
      "skipped 4\n",
      "skipped 5\n",
      "skipped 6\n",
      "skipped 7\n",
      "skipped 8\n",
      "skipped 9\n",
      "skipped 10\n",
      "skipped 11\n",
      "skipped 12\n",
      "skipped 13\n",
      "skipped 14\n",
      "skipped 15\n",
      "skipped 16\n",
      "skipped 17\n",
      "skipped 18\n",
      "skipped 19\n",
      "skipped 20\n",
      "skipped 21\n",
      "skipped 22\n",
      "skipped 23\n",
      "skipped 24\n",
      "skipped 25\n",
      "skipped 26\n",
      "skipped 27\n",
      "skipped 28\n",
      "skipped 29\n",
      "skipped 30\n",
      "skipped 31\n",
      "skipped 32\n",
      "skipped 33\n",
      "skipped 34\n",
      "skipped 35\n",
      "skipped 36\n",
      "skipped 37\n",
      "skipped 38\n",
      "skipped 39\n",
      "skipped 40\n",
      "skipped 41\n",
      "skipped 42\n",
      "skipped 43\n",
      "skipped 44\n",
      "skipped 45\n",
      "skipped 46\n",
      "skipped 47\n",
      "skipped 48\n",
      "skipped 49\n",
      "skipped 50\n",
      "skipped 51\n",
      "skipped 52\n",
      "skipped 53\n",
      "skipped 54\n",
      "skipped 55\n",
      "skipped 56\n",
      "skipped 57\n",
      "skipped 58\n",
      "skipped 59\n",
      "skipped 60\n",
      "skipped 61\n",
      "skipped 62\n",
      "skipped 63\n",
      "skipped 64\n",
      "skipped 65\n",
      "skipped 66\n",
      "skipped 67\n",
      "skipped 68\n",
      "skipped 69\n",
      "skipped 70\n",
      "skipped 71\n",
      "skipped 72\n",
      "skipped 73\n",
      "skipped 74\n",
      "skipped 75\n",
      "skipped 76\n",
      "skipped 77\n",
      "skipped 78\n",
      "skipped 79\n",
      "skipped 80\n",
      "skipped 81\n",
      "skipped 82\n",
      "skipped 83\n",
      "skipped 84\n",
      "skipped 85\n",
      "skipped 86\n",
      "skipped 87\n",
      "skipped 88\n",
      "skipped 89\n",
      "skipped 90\n",
      "skipped 91\n",
      "skipped 92\n",
      "skipped 93\n",
      "skipped 94\n",
      "skipped 95\n",
      "skipped 96\n",
      "skipped 97\n",
      "skipped 98\n",
      "skipped 99\n",
      "skipped 100\n",
      "skipped 101\n",
      "skipped 102\n",
      "skipped 103\n",
      "skipped 104\n",
      "skipped 105\n",
      "skipped 106\n",
      "skipped 107\n",
      "skipped 108\n",
      "skipped 109\n",
      "skipped 110\n",
      "skipped 111\n",
      "skipped 112\n",
      "skipped 113\n",
      "skipped 114\n",
      "skipped 115\n",
      "skipped 116\n",
      "skipped 117\n",
      "skipped 118\n",
      "skipped 119\n",
      "skipped 120\n",
      "skipped 121\n",
      "skipped 122\n",
      "skipped 123\n",
      "skipped 124\n",
      "skipped 125\n",
      "skipped 126\n",
      "skipped 127\n",
      "skipped 128\n",
      "skipped 129\n",
      "skipped 130\n",
      "skipped 131\n",
      "skipped 132\n",
      "skipped 133\n",
      "skipped 134\n",
      "skipped 135\n",
      "skipped 136\n",
      "skipped 137\n",
      "skipped 138\n",
      "skipped 139\n",
      "skipped 140\n",
      "skipped 141\n",
      "skipped 142\n",
      "skipped 143\n",
      "skipped 144\n",
      "skipped 145\n",
      "skipped 146\n",
      "skipped 147\n",
      "skipped 148\n",
      "skipped 149\n",
      "skipped 150\n",
      "skipped 151\n",
      "skipped 152\n",
      "skipped 153\n",
      "skipped 154\n",
      "skipped 155\n",
      "skipped 156\n",
      "skipped 157\n",
      "skipped 158\n",
      "skipped 159\n",
      "skipped 160\n",
      "skipped 161\n",
      "skipped 162\n",
      "skipped 163\n",
      "skipped 164\n",
      "skipped 165\n",
      "skipped 166\n",
      "skipped 167\n",
      "skipped 168\n",
      "skipped 169\n",
      "skipped 170\n",
      "skipped 171\n",
      "skipped 172\n",
      "skipped 173\n",
      "skipped 174\n",
      "skipped 175\n",
      "skipped 176\n",
      "skipped 177\n",
      "skipped 178\n",
      "skipped 179\n",
      "skipped 180\n",
      "skipped 181\n",
      "skipped 182\n",
      "skipped 183\n",
      "skipped 184\n",
      "skipped 185\n",
      "skipped 186\n",
      "skipped 187\n",
      "skipped 188\n",
      "skipped 189\n",
      "skipped 190\n",
      "skipped 191\n",
      "skipped 192\n",
      "skipped 193\n",
      "skipped 194\n",
      "skipped 195\n",
      "skipped 196\n",
      "skipped 197\n",
      "skipped 198\n",
      "skipped 199\n",
      "skipped 200\n",
      "skipped 201\n",
      "skipped 202\n",
      "skipped 203\n",
      "skipped 204\n",
      "skipped 205\n",
      "skipped 206\n",
      "skipped 207\n",
      "skipped 208\n",
      "skipped 209\n",
      "skipped 210\n",
      "skipped 211\n",
      "skipped 212\n",
      "skipped 213\n",
      "skipped 214\n",
      "skipped 215\n",
      "skipped 216\n",
      "skipped 217\n",
      "skipped 218\n",
      "skipped 219\n",
      "skipped 220\n",
      "skipped 221\n",
      "skipped 222\n",
      "skipped 223\n",
      "skipped 224\n",
      "skipped 225\n",
      "skipped 226\n",
      "skipped 227\n",
      "skipped 228\n",
      "skipped 229\n",
      "skipped 230\n",
      "skipped 231\n",
      "skipped 232\n",
      "skipped 233\n",
      "skipped 234\n",
      "skipped 235\n",
      "skipped 236\n",
      "skipped 237\n",
      "skipped 238\n",
      "skipped 239\n",
      "skipped 240\n",
      "skipped 241\n",
      "skipped 242\n",
      "skipped 243\n",
      "skipped 244\n",
      "skipped 245\n",
      "skipped 246\n",
      "skipped 247\n",
      "skipped 248\n",
      "skipped 249\n",
      "skipped 250\n",
      "skipped 251\n",
      "skipped 252\n",
      "skipped 253\n",
      "skipped 254\n",
      "skipped 255\n",
      "skipped 256\n",
      "skipped 257\n",
      "skipped 258\n",
      "skipped 259\n",
      "skipped 260\n",
      "skipped 261\n",
      "skipped 262\n",
      "skipped 263\n",
      "skipped 264\n",
      "skipped 265\n",
      "skipped 266\n",
      "skipped 267\n",
      "skipped 268\n",
      "skipped 269\n",
      "skipped 270\n",
      "skipped 271\n",
      "skipped 272\n",
      "skipped 273\n",
      "skipped 274\n",
      "skipped 275\n",
      "skipped 276\n",
      "skipped 277\n",
      "skipped 278\n",
      "skipped 279\n",
      "skipped 280\n",
      "skipped 281\n",
      "skipped 282\n",
      "skipped 283\n",
      "skipped 284\n",
      "skipped 285\n",
      "skipped 286\n",
      "skipped 287\n",
      "skipped 288\n",
      "skipped 289\n",
      "skipped 290\n",
      "skipped 291\n",
      "skipped 292\n",
      "skipped 293\n",
      "skipped 294\n",
      "skipped 295\n",
      "skipped 296\n",
      "skipped 297\n",
      "skipped 298\n",
      "skipped 299\n",
      "skipped 300\n",
      "skipped 301\n",
      "skipped 302\n",
      "skipped 303\n",
      "skipped 304\n",
      "skipped 305\n",
      "skipped 306\n",
      "skipped 307\n",
      "skipped 308\n",
      "skipped 309\n",
      "skipped 310\n",
      "skipped 311\n",
      "skipped 312\n",
      "skipped 313\n",
      "skipped 314\n",
      "skipped 315\n",
      "skipped 316\n",
      "skipped 317\n",
      "skipped 318\n",
      "skipped 319\n",
      "skipped 320\n",
      "skipped 321\n",
      "skipped 322\n",
      "skipped 323\n",
      "skipped 324\n",
      "skipped 325\n",
      "skipped 326\n",
      "skipped 327\n",
      "skipped 328\n",
      "skipped 329\n",
      "skipped 330\n",
      "skipped 331\n",
      "skipped 332\n",
      "skipped 333\n",
      "skipped 334\n",
      "skipped 335\n",
      "skipped 336\n",
      "skipped 337\n",
      "skipped 338\n",
      "skipped 339\n",
      "skipped 340\n",
      "skipped 341\n",
      "skipped 342\n",
      "skipped 343\n",
      "skipped 344\n",
      "skipped 345\n",
      "skipped 346\n",
      "skipped 347\n",
      "skipped 348\n",
      "skipped 349\n",
      "skipped 350\n",
      "skipped 351\n",
      "skipped 352\n",
      "skipped 353\n",
      "skipped 354\n",
      "skipped 355\n",
      "skipped 356\n",
      "skipped 357\n",
      "skipped 358\n",
      "skipped 359\n",
      "skipped 360\n",
      "skipped 361\n",
      "skipped 362\n",
      "skipped 363\n",
      "skipped 364\n",
      "skipped 365\n",
      "skipped 366\n",
      "skipped 367\n",
      "skipped 368\n",
      "skipped 369\n",
      "skipped 370\n",
      "skipped 371\n",
      "skipped 372\n",
      "skipped 373\n",
      "skipped 374\n",
      "skipped 375\n",
      "skipped 376\n",
      "skipped 377\n",
      "skipped 378\n",
      "skipped 379\n",
      "skipped 380\n",
      "skipped 381\n",
      "skipped 382\n",
      "skipped 383\n",
      "skipped 384\n",
      "skipped 385\n",
      "skipped 386\n",
      "skipped 387\n",
      "skipped 388\n",
      "skipped 389\n",
      "skipped 390\n",
      "skipped 391\n",
      "skipped 392\n",
      "skipped 393\n",
      "skipped 394\n",
      "skipped 395\n",
      "skipped 396\n",
      "skipped 397\n",
      "skipped 398\n",
      "skipped 399\n",
      "skipped 400\n",
      "skipped 401\n",
      "skipped 402\n",
      "skipped 403\n",
      "skipped 404\n",
      "skipped 405\n",
      "skipped 406\n",
      "skipped 407\n",
      "skipped 408\n",
      "skipped 409\n",
      "skipped 410\n",
      "skipped 411\n",
      "skipped 412\n",
      "skipped 413\n",
      "skipped 414\n",
      "skipped 415\n",
      "skipped 416\n",
      "skipped 417\n",
      "skipped 418\n",
      "skipped 419\n",
      "skipped 420\n",
      "skipped 421\n",
      "skipped 422\n",
      "skipped 423\n",
      "skipped 424\n",
      "skipped 425\n",
      "skipped 426\n",
      "skipped 427\n",
      "skipped 428\n",
      "skipped 429\n",
      "skipped 430\n",
      "skipped 431\n",
      "skipped 432\n",
      "skipped 433\n",
      "skipped 434\n",
      "skipped 435\n",
      "skipped 436\n",
      "skipped 437\n",
      "skipped 438\n",
      "skipped 439\n",
      "skipped 440\n",
      "skipped 441\n",
      "skipped 442\n",
      "skipped 443\n",
      "skipped 444\n",
      "skipped 445\n",
      "skipped 446\n",
      "skipped 447\n",
      "skipped 448\n",
      "skipped 449\n",
      "skipped 450\n",
      "skipped 451\n",
      "skipped 452\n",
      "skipped 453\n",
      "skipped 454\n",
      "skipped 455\n",
      "skipped 456\n",
      "skipped 457\n",
      "skipped 458\n",
      "skipped 459\n",
      "skipped 460\n",
      "skipped 461\n",
      "skipped 462\n",
      "skipped 463\n",
      "skipped 464\n",
      "skipped 465\n",
      "skipped 466\n",
      "skipped 467\n",
      "skipped 468\n",
      "skipped 469\n",
      "skipped 470\n",
      "skipped 471\n",
      "skipped 472\n",
      "skipped 473\n",
      "skipped 474\n",
      "skipped 475\n",
      "skipped 476\n",
      "skipped 477\n",
      "skipped 478\n",
      "skipped 479\n",
      "skipped 480\n",
      "skipped 481\n",
      "skipped 482\n",
      "skipped 483\n",
      "skipped 484\n",
      "skipped 485\n",
      "skipped 486\n",
      "skipped 487\n",
      "skipped 488\n",
      "skipped 489\n",
      "skipped 490\n",
      "skipped 491\n",
      "skipped 492\n",
      "skipped 493\n",
      "skipped 494\n",
      "skipped 495\n",
      "skipped 496\n",
      "skipped 497\n",
      "skipped 498\n",
      "skipped 499\n",
      "skipped 500\n",
      "skipped 501\n",
      "skipped 502\n",
      "skipped 503\n",
      "skipped 504\n",
      "skipped 505\n",
      "skipped 506\n",
      "skipped 507\n",
      "skipped 508\n",
      "skipped 509\n",
      "skipped 510\n",
      "skipped 511\n",
      "skipped 512\n",
      "skipped 513\n",
      "skipped 514\n",
      "skipped 515\n",
      "skipped 516\n",
      "skipped 517\n",
      "skipped 518\n",
      "skipped 519\n",
      "skipped 520\n",
      "skipped 521\n",
      "skipped 522\n",
      "skipped 523\n",
      "skipped 524\n",
      "skipped 525\n",
      "skipped 526\n",
      "skipped 527\n",
      "skipped 528\n",
      "skipped 529\n",
      "skipped 530\n",
      "skipped 531\n",
      "skipped 532\n",
      "skipped 533\n",
      "skipped 534\n",
      "skipped 535\n",
      "skipped 536\n",
      "skipped 537\n",
      "skipped 538\n",
      "skipped 539\n",
      "skipped 540\n",
      "skipped 541\n",
      "skipped 542\n",
      "skipped 543\n",
      "skipped 544\n",
      "skipped 545\n",
      "skipped 546\n",
      "skipped 547\n",
      "skipped 548\n",
      "skipped 549\n",
      "skipped 550\n",
      "skipped 551\n",
      "skipped 552\n",
      "skipped 553\n",
      "skipped 554\n",
      "skipped 555\n",
      "skipped 556\n",
      "skipped 557\n",
      "skipped 558\n",
      "skipped 559\n",
      "skipped 560\n",
      "skipped 561\n",
      "skipped 562\n",
      "skipped 563\n",
      "skipped 564\n",
      "skipped 565\n",
      "skipped 566\n",
      "skipped 567\n",
      "skipped 568\n",
      "skipped 569\n",
      "skipped 570\n",
      "skipped 571\n",
      "skipped 572\n",
      "skipped 573\n",
      "skipped 574\n",
      "skipped 575\n",
      "skipped 576\n",
      "skipped 577\n",
      "skipped 578\n",
      "skipped 579\n",
      "skipped 580\n",
      "skipped 581\n",
      "skipped 582\n",
      "skipped 583\n",
      "skipped 584\n",
      "skipped 585\n",
      "skipped 586\n",
      "skipped 587\n",
      "skipped 588\n",
      "skipped 589\n",
      "skipped 590\n",
      "skipped 591\n",
      "skipped 592\n",
      "skipped 593\n",
      "skipped 594\n",
      "skipped 595\n",
      "skipped 596\n",
      "skipped 597\n",
      "skipped 598\n",
      "skipped 599\n",
      "skipped 600\n",
      "skipped 601\n",
      "skipped 602\n",
      "skipped 603\n",
      "skipped 604\n",
      "skipped 605\n",
      "skipped 606\n",
      "skipped 607\n",
      "skipped 608\n",
      "skipped 609\n",
      "skipped 610\n",
      "skipped 611\n",
      "skipped 612\n",
      "skipped 613\n",
      "skipped 614\n",
      "skipped 615\n",
      "skipped 616\n",
      "skipped 617\n",
      "skipped 618\n",
      "skipped 619\n",
      "skipped 620\n",
      "skipped 621\n",
      "skipped 622\n",
      "skipped 623\n",
      "skipped 624\n",
      "skipped 625\n",
      "skipped 626\n",
      "skipped 627\n",
      "skipped 628\n",
      "skipped 629\n",
      "skipped 630\n",
      "skipped 631\n",
      "skipped 632\n",
      "skipped 633\n",
      "skipped 634\n",
      "skipped 635\n",
      "skipped 636\n",
      "skipped 637\n",
      "skipped 638\n",
      "skipped 639\n",
      "skipped 640\n",
      "skipped 641\n",
      "skipped 642\n",
      "skipped 643\n",
      "skipped 644\n",
      "skipped 645\n",
      "skipped 646\n",
      "skipped 647\n",
      "skipped 648\n",
      "skipped 649\n",
      "skipped 650\n",
      "skipped 651\n",
      "skipped 652\n",
      "skipped 653\n",
      "skipped 654\n",
      "skipped 655\n",
      "skipped 656\n",
      "skipped 657\n",
      "skipped 658\n",
      "skipped 659\n",
      "skipped 660\n",
      "skipped 661\n",
      "skipped 662\n",
      "skipped 663\n",
      "skipped 664\n",
      "skipped 665\n",
      "skipped 666\n",
      "skipped 667\n",
      "skipped 668\n",
      "skipped 669\n",
      "skipped 670\n",
      "skipped 671\n",
      "skipped 672\n",
      "skipped 673\n",
      "skipped 674\n",
      "skipped 675\n",
      "skipped 676\n",
      "skipped 677\n",
      "skipped 678\n",
      "skipped 679\n",
      "skipped 680\n",
      "skipped 681\n",
      "skipped 682\n",
      "skipped 683\n",
      "skipped 684\n",
      "skipped 685\n",
      "skipped 686\n",
      "skipped 687\n",
      "skipped 688\n",
      "skipped 689\n",
      "skipped 690\n",
      "skipped 691\n",
      "skipped 692\n",
      "skipped 693\n",
      "skipped 694\n",
      "skipped 695\n",
      "skipped 696\n",
      "skipped 697\n",
      "skipped 698\n",
      "skipped 699\n",
      "skipped 700\n",
      "skipped 701\n",
      "skipped 702\n",
      "skipped 703\n",
      "skipped 704\n",
      "skipped 705\n",
      "skipped 706\n",
      "skipped 707\n",
      "skipped 708\n",
      "skipped 709\n",
      "skipped 710\n",
      "skipped 711\n",
      "skipped 712\n",
      "skipped 713\n",
      "skipped 714\n",
      "skipped 715\n",
      "skipped 716\n",
      "skipped 717\n",
      "skipped 718\n",
      "skipped 719\n",
      "skipped 720\n",
      "skipped 721\n",
      "skipped 722\n",
      "skipped 723\n",
      "skipped 724\n",
      "skipped 725\n",
      "skipped 726\n",
      "skipped 727\n",
      "skipped 728\n",
      "skipped 729\n",
      "skipped 730\n",
      "skipped 731\n",
      "skipped 732\n",
      "skipped 733\n",
      "skipped 734\n",
      "skipped 735\n",
      "skipped 736\n",
      "skipped 737\n",
      "skipped 738\n",
      "skipped 739\n",
      "skipped 740\n",
      "skipped 741\n",
      "skipped 742\n",
      "skipped 743\n",
      "skipped 744\n",
      "skipped 745\n",
      "skipped 746\n",
      "skipped 747\n",
      "skipped 748\n",
      "skipped 749\n",
      "skipped 750\n",
      "skipped 751\n"
     ]
    }
   ],
   "source": [
    "key_path = os.environ.get(\"ENCORD_SSH_KEY_FILE\")\n",
    "\n",
    "user_client: EncordUserClient = EncordUserClient.create_with_ssh_private_key(\n",
    "    ssh_private_key_path=key_path\n",
    ")\n",
    "\n",
    "\n",
    "above_folder_name = 'Encord Documentation Above Text'\n",
    "below_folder_name = 'Encord Documentation Below Text'\n",
    "\n",
    "afolders = list(user_client.find_storage_folders(search=above_folder_name, page_size=1))\n",
    "a_storage_folder = afolders[0] \n",
    "bfolders = list(user_client.find_storage_folders(search=below_folder_name, page_size=1))\n",
    "b_storage_folder = bfolders[0] \n",
    "\n",
    "\n",
    "for i,row in enumerate(test_df.iterrows()):\n",
    "    # if i < 752:\n",
    "    #     print(f'skipped {i}')\n",
    "    #     continue\n",
    "    \n",
    "    img_url = row[1]['image url']\n",
    "\n",
    "    if 'gif' not in img_url:\n",
    "        print(f'processing {i}')\n",
    "        atext_path = f'above_text/above_text_{i}.txt'\n",
    "        btext_path = f'below_text/below_text_{i}.txt'\n",
    "        above_metadata = {\"id\" : str(i), \"Data_Type\" : \"above_text\"}\n",
    "        below_metadata = {\"id\" : str(i), \"Data_Type\" : \"below_text\"}\n",
    "\n",
    "        a_storage_folder.upload_text(atext_path,client_metadata=above_metadata)\n",
    "        b_storage_folder.upload_text(btext_path,client_metadata=below_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Help me create a question-answer dataset for my application. You have access to a screenshot of the application from the documentation and the surrounding text above and below it:\\n\\n    === documentation text above image ===\\n    1. In the Encord platform, select _Projects_ under _Annotate_.\\n2. Select the Project you want to Manage.\\n\\n    === documentation text below image ===\\n    The dashboard is split into the following tabs:\\n\\n- **Project Overview**: High-level view of labeling and productivity statistics.\\n- **Explore**: Explore the distribution of instances and labels across data assets in the project.\\n- **Queue**: Shows all tasks in the Project by Workflow stage.\\n- **Workflow**: Graphically displays the path tasks follow through the Project Workflow.\\n- **Labels & Export**: For managing all the Project\\'s labels, including exporting labels.\\n- **Analytics**: Detailed Project analytics.\\n- **Settings**: Manage your Project Settings, including copying Projects, managing Project tags, customizing editor layouts, and deleting Projects.\\n\\n    ==== instructions ===\\n    Thoroughly review the screenshot, imagining you are a user interacting with the application in a context similar to what is shown. Based on that situation, propose three realistic questions that such a user might ask, and then provide accurate answers to each question based on the documentation text. If the documentation text is not informative enough, come up with question-answer pairs using the screenshot only. Ensure the questions are realistic but sufficiently diverse. The questions and answers ***must*** refer to the image.\\n\\n    Please follow the JSON Schema to indicate your response.\\n    Don\\'t respond with anything but valid json.\\n\\n    === JSON Schema ===\\n    {\"$defs\": {\"QuestionAnswerPair1RadioModel\": {\"properties\": {\"feature_node_hash\": {\"const\": \"D9oJlIXz\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"choice\": {\"description\": \"Choose exactly one answer from the given options.\", \"discriminator\": {\"mapping\": {\"5qvmjZEN\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__1\"}, \"propertyName\": \"feature_node_hash\"}, \"oneOf\": [{\"$ref\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__1\"}], \"title\": \"Choice\"}}, \"required\": [\"feature_node_hash\", \"choice\"], \"title\": \"QuestionAnswerPair1RadioModel\", \"type\": \"object\"}, \"QuestionAnswerPair2RadioModel\": {\"properties\": {\"feature_node_hash\": {\"const\": \"jat0dizi\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"choice\": {\"description\": \"Choose exactly one answer from the given options.\", \"discriminator\": {\"mapping\": {\"7ew0GaDG\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__2\"}, \"propertyName\": \"feature_node_hash\"}, \"oneOf\": [{\"$ref\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__2\"}], \"title\": \"Choice\"}}, \"required\": [\"feature_node_hash\", \"choice\"], \"title\": \"QuestionAnswerPair2RadioModel\", \"type\": \"object\"}, \"QuestionAnswerPair3RadioModel\": {\"properties\": {\"feature_node_hash\": {\"const\": \"cZsafTBg\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"choice\": {\"description\": \"Choose exactly one answer from the given options.\", \"discriminator\": {\"mapping\": {\"FVgOeelB\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__3\"}, \"propertyName\": \"feature_node_hash\"}, \"oneOf\": [{\"$ref\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__3\"}], \"title\": \"Choice\"}}, \"required\": [\"feature_node_hash\", \"choice\"], \"title\": \"QuestionAnswerPair3RadioModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__AnswerTextModel__1\": {\"properties\": {\"feature_node_hash\": {\"const\": \"4mvdzZ+c\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Answer\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"AnswerTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__AnswerTextModel__2\": {\"properties\": {\"feature_node_hash\": {\"const\": \"RtwPHjxE\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Answer\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"AnswerTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__AnswerTextModel__3\": {\"properties\": {\"feature_node_hash\": {\"const\": \"PV+lOe7L\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Answer\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"AnswerTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QaPairNestedRadioModel__1\": {\"properties\": {\"feature_node_hash\": {\"const\": \"5qvmjZEN\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"question\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__QuestionTextModel__1\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}, \"answer\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__AnswerTextModel__1\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}}, \"required\": [\"feature_node_hash\", \"question\", \"answer\"], \"title\": \"QaPairNestedRadioModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QaPairNestedRadioModel__2\": {\"properties\": {\"feature_node_hash\": {\"const\": \"7ew0GaDG\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"question\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__QuestionTextModel__2\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}, \"answer\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__AnswerTextModel__2\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}}, \"required\": [\"feature_node_hash\", \"question\", \"answer\"], \"title\": \"QaPairNestedRadioModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QaPairNestedRadioModel__3\": {\"properties\": {\"feature_node_hash\": {\"const\": \"FVgOeelB\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"question\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__QuestionTextModel__3\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}, \"answer\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__AnswerTextModel__3\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}}, \"required\": [\"feature_node_hash\", \"question\", \"answer\"], \"title\": \"QaPairNestedRadioModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QuestionTextModel__1\": {\"properties\": {\"feature_node_hash\": {\"const\": \"L27fSN3D\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Question\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"QuestionTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QuestionTextModel__2\": {\"properties\": {\"feature_node_hash\": {\"const\": \"yZdu3EEi\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Question\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"QuestionTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QuestionTextModel__3\": {\"properties\": {\"feature_node_hash\": {\"const\": \"8IpLiz/c\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Question\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"QuestionTextModel\", \"type\": \"object\"}}, \"properties\": {\"question_answer_pair_1\": {\"$ref\": \"#/$defs/QuestionAnswerPair1RadioModel\", \"description\": \"A mutually exclusive radio attribute to choose exactly one option that best matches to the give visual input.\"}, \"question_answer_pair_2\": {\"$ref\": \"#/$defs/QuestionAnswerPair2RadioModel\", \"description\": \"A mutually exclusive radio attribute to choose exactly one option that best matches to the give visual input.\"}, \"question_answer_pair_3\": {\"$ref\": \"#/$defs/QuestionAnswerPair3RadioModel\", \"description\": \"A mutually exclusive radio attribute to choose exactly one option that best matches to the give visual input.\"}}, \"required\": [\"question_answer_pair_1\", \"question_answer_pair_2\", \"question_answer_pair_3\"], \"title\": \"ClassificationModel\", \"type\": \"object\"}\\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Help me create a question-answer dataset for my application. You have access to a screenshot of the application from the documentation and the surrounding text above and below it:\\n\\n    === documentation text above image ===\\n    1. In the Encord platform, select _Projects_ under _Annotate_.\\n2. Select the Project you want to Manage.\\n\\n    === documentation text below image ===\\n    The dashboard is split into the following tabs:\\n\\n- **Project Overview**: High-level view of labeling and productivity statistics.\\n- **Explore**: Explore the distribution of instances and labels across data assets in the project.\\n- **Queue**: Shows all tasks in the Project by Workflow stage.\\n- **Workflow**: Graphically displays the path tasks follow through the Project Workflow.\\n- **Labels & Export**: For managing all the Project\\'s labels, including exporting labels.\\n- **Analytics**: Detailed Project analytics.\\n- **Settings**: Manage your Project Settings, including copying Projects, managing Project tags, customizing editor layouts, and deleting Projects.\\n\\n    ==== instructions ===\\n    Thoroughly review the screenshot, imagining you are a user interacting with the application in a context similar to what is shown. Based on that situation, propose three realistic questions that such a user might ask, and then provide accurate answers to each question based on the documentation text. If the documentation text is not informative enough, come up with question-answer pairs using the screenshot only. Ensure the questions are realistic but sufficiently diverse. The questions and answers ***must*** refer to the image.\\n\\n    Please follow the JSON Schema to indicate your response.\\n    Don\\'t respond with anything but valid json.\\n\\n    === JSON Schema ===\\n    {\"$defs\": {\"QuestionAnswerPair1RadioModel\": {\"properties\": {\"feature_node_hash\": {\"const\": \"D9oJlIXz\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"choice\": {\"description\": \"Choose exactly one answer from the given options.\", \"discriminator\": {\"mapping\": {\"5qvmjZEN\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__1\"}, \"propertyName\": \"feature_node_hash\"}, \"oneOf\": [{\"$ref\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__1\"}], \"title\": \"Choice\"}}, \"required\": [\"feature_node_hash\", \"choice\"], \"title\": \"QuestionAnswerPair1RadioModel\", \"type\": \"object\"}, \"QuestionAnswerPair2RadioModel\": {\"properties\": {\"feature_node_hash\": {\"const\": \"jat0dizi\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"choice\": {\"description\": \"Choose exactly one answer from the given options.\", \"discriminator\": {\"mapping\": {\"7ew0GaDG\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__2\"}, \"propertyName\": \"feature_node_hash\"}, \"oneOf\": [{\"$ref\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__2\"}], \"title\": \"Choice\"}}, \"required\": [\"feature_node_hash\", \"choice\"], \"title\": \"QuestionAnswerPair2RadioModel\", \"type\": \"object\"}, \"QuestionAnswerPair3RadioModel\": {\"properties\": {\"feature_node_hash\": {\"const\": \"cZsafTBg\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"choice\": {\"description\": \"Choose exactly one answer from the given options.\", \"discriminator\": {\"mapping\": {\"FVgOeelB\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__3\"}, \"propertyName\": \"feature_node_hash\"}, \"oneOf\": [{\"$ref\": \"#/$defs/encord_agents__core__ontology__QaPairNestedRadioModel__3\"}], \"title\": \"Choice\"}}, \"required\": [\"feature_node_hash\", \"choice\"], \"title\": \"QuestionAnswerPair3RadioModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__AnswerTextModel__1\": {\"properties\": {\"feature_node_hash\": {\"const\": \"4mvdzZ+c\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Answer\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"AnswerTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__AnswerTextModel__2\": {\"properties\": {\"feature_node_hash\": {\"const\": \"RtwPHjxE\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Answer\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"AnswerTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__AnswerTextModel__3\": {\"properties\": {\"feature_node_hash\": {\"const\": \"PV+lOe7L\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Answer\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"AnswerTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QaPairNestedRadioModel__1\": {\"properties\": {\"feature_node_hash\": {\"const\": \"5qvmjZEN\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"question\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__QuestionTextModel__1\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}, \"answer\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__AnswerTextModel__1\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}}, \"required\": [\"feature_node_hash\", \"question\", \"answer\"], \"title\": \"QaPairNestedRadioModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QaPairNestedRadioModel__2\": {\"properties\": {\"feature_node_hash\": {\"const\": \"7ew0GaDG\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"question\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__QuestionTextModel__2\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}, \"answer\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__AnswerTextModel__2\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}}, \"required\": [\"feature_node_hash\", \"question\", \"answer\"], \"title\": \"QaPairNestedRadioModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QaPairNestedRadioModel__3\": {\"properties\": {\"feature_node_hash\": {\"const\": \"FVgOeelB\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"question\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__QuestionTextModel__3\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}, \"answer\": {\"$ref\": \"#/$defs/encord_agents__core__ontology__AnswerTextModel__3\", \"description\": \"A text attribute with carefully crafted text to describe the property.\"}}, \"required\": [\"feature_node_hash\", \"question\", \"answer\"], \"title\": \"QaPairNestedRadioModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QuestionTextModel__1\": {\"properties\": {\"feature_node_hash\": {\"const\": \"L27fSN3D\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Question\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"QuestionTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QuestionTextModel__2\": {\"properties\": {\"feature_node_hash\": {\"const\": \"yZdu3EEi\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Question\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"QuestionTextModel\", \"type\": \"object\"}, \"encord_agents__core__ontology__QuestionTextModel__3\": {\"properties\": {\"feature_node_hash\": {\"const\": \"8IpLiz/c\", \"description\": \"UUID for discrimination. Must be included in json as is.\", \"title\": \"Feature Node Hash\", \"type\": \"string\"}, \"value\": {\"description\": \"Please describe the image as accurate as possible focusing on \\'Question\\'\", \"maxLength\": 1000, \"minLength\": 0, \"title\": \"Value\", \"type\": \"string\"}}, \"required\": [\"feature_node_hash\", \"value\"], \"title\": \"QuestionTextModel\", \"type\": \"object\"}}, \"properties\": {\"question_answer_pair_1\": {\"$ref\": \"#/$defs/QuestionAnswerPair1RadioModel\", \"description\": \"A mutually exclusive radio attribute to choose exactly one option that best matches to the give visual input.\"}, \"question_answer_pair_2\": {\"$ref\": \"#/$defs/QuestionAnswerPair2RadioModel\", \"description\": \"A mutually exclusive radio attribute to choose exactly one option that best matches to the give visual input.\"}, \"question_answer_pair_3\": {\"$ref\": \"#/$defs/QuestionAnswerPair3RadioModel\", \"description\": \"A mutually exclusive radio attribute to choose exactly one option that best matches to the give visual input.\"}}, \"required\": [\"question_answer_pair_1\", \"question_answer_pair_2\", \"question_answer_pair_3\"], \"title\": \"ClassificationModel\", \"type\": \"object\"}\\n    '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b64_frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[270], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m response \u001b[38;5;241m=\u001b[39m openai_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m         {\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m----> 6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\u001b[43mb64_frame\u001b[49m ],\n\u001b[1;32m      7\u001b[0m         }\n\u001b[1;32m      8\u001b[0m     ],\n\u001b[1;32m      9\u001b[0m     response_format\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m model_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get resp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b64_frame' is not defined"
     ]
    }
   ],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt},fr ],\n",
    "        }\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "model_response = response.choices[0].message.content or \"Failed to get resp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm-dataset-creation-jeIslTpk-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
